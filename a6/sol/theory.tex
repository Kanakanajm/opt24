\documentclass{article}

% Packages forked from the original template
\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}

% Extra packages
\usepackage{changepage} % adjustwidth environment
\usepackage{hyperref} % href
\usepackage{xcolor} % colored text

\usetikzlibrary{automata,positioning}

% Additional commands
\def\eg{\emph{e.g., }}
\def\ie{\emph{i.e., }}
\def\cf{\emph{c.f., }}
\def\etc{\emph{etc. }}
\def\wrt{\emph{w.r.t. }}
\def\etal{\emph{et al. }}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkClass: \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Exercise \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Exercise \arabic{#1} (continued)}{Exercise \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Exercise \arabic{#1} (continued)}{Exercise \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Exercise \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Exercise \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Exercise \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Assignment 6}
\newcommand{\hmwkDueDate}{June 4, 2024}
\newcommand{\hmwkClass}{Continuous Optimization}
\newcommand{\hmwkAuthorName}{ \textbf{Honglu Ma} \and \textbf{Hiroyasu Akada} \and \textbf{Mathivathana Ayyappan}}

%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{3in}
}

\author{\hmwkAuthorName}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}

% Norm
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}

% Margined Homework Subsection
\newenvironment{homeworkSubsection}[1]{%
    \subsection*{#1}%
    \begin{adjustwidth}{2.5em}{0pt}%
}{%
    \end{adjustwidth}%
}

\begin{document}

\maketitle

\pagebreak

\begin{homeworkProblem}[1]
    The strong Wolfe condition states that for some $\eta \in (\gamma, 1), \gamma \in (0, 1)$, the following holds:
    \[
        \left|\langle\nabla f(x^{(k)} + \tau_k d^{(k)}), d^{(k)}\rangle\right| \leq \eta\left|\langle\nabla f(x^{(k)}), d^{(k)}\rangle\right|
    \]
    We know the iterative update step for $x^{(k+1)}$ is defined as: $x^{(k+1)} = x^{(k)} + \tau_k d^{(k)}$.
    The strong curvature condition can be rewritten as such:
    \[
        \left|\langle\nabla f(x^{(k+1)}), d^{(k)}\rangle\right| \leq \eta\left|\langle\nabla f(x^{(k)}), d^{(k)}\rangle\right|
    \]
    By the definition of descent direction, $\langle\nabla f(x^{(k)}), d^{(k)}\rangle < 0$ and $\eta > 0$, we get
    \begin{align*}
        \langle\nabla f(x^{(k+1)}), d^{(k)}\rangle &\geq \eta\langle\nabla f(x^{(k)}), d^{(k)}\rangle\\
        \langle\nabla f(x^{(k+1)}), d^{(k)}\rangle - \langle\nabla f(x^{(k)}), d^{(k)}\rangle 
        &\geq \eta\langle\nabla f(x^{(k)}), d^{(k)}\rangle - \langle\nabla f(x^{(k)}), d^{(k)}\rangle\\
        \langle\nabla f(x^{(k+1)}) - \nabla f(x^{(k)}), d^{(k)}\rangle
        &\geq (\eta - 1)\langle\nabla f(x^{(k)}), d^{(k)}\rangle > 0\\
    \end{align*}
    We know $\tau_k > 0$
    \begin{align*}
        \langle\nabla f(x^{(k+1)}) - \nabla f(x^{(k)}), \tau_k d^{(k)}\rangle &> 0\\
        \langle\nabla f(x^{(k+1)}) - \nabla f(x^{(k)}), x^{(k+1)} - x^{(k)}\rangle &> 0\\
        \langle y^{(k)}, s^{(k)}\rangle &> 0\\
    \end{align*}

\end{homeworkProblem}
\begin{homeworkProblem}[2]
    The secant equation is given by $B_{k+1} s^{(k)} = y^{(k)}$
    which is a system of $n$ linear equations (assume the dimension is $n$).
    The choice of $B_{k+1}$ is constrained by these $n$ equations which results in a degree of freedom of $n$.

    On the other hand, the curvature condition:
    \begin{align*}
        \langle s^{(k)}, B_{k+1} s^{(k)}\rangle &= \langle s^{(k)}, y^{(k)}\rangle\\
        \langle s^{(k)}, B_{k+1} s^{(k)}\rangle - \langle s^{(k)}, y^{(k)}\rangle &= 0\\
        \langle s^{(k)}, B_{k+1} s^{(k)}-y^{(k)}\rangle &= 0\\
    \end{align*}
    It can be satisfied not only by setting $B_{k+1} s^{(k)}-y^{(k)} = 0$ 
    which is the same as the secant equation, but also by setting $B_{k+1} s^{(k)}-y^{(k)}$ to be orthogonal to $s^{(k)}$.
    This gives more degree of freedom of choosing $B_{k+1}$.
\end{homeworkProblem}
\begin{homeworkProblem}[3]
    
\end{homeworkProblem}
\begin{homeworkProblem}[4]
    \begin{homeworkSubsection}{(a)}
        An useful identity:
        \[
            1 - h_w(x) = \frac{e^{-\langle w, x\rangle}}{1 + e^{-\langle w, x\rangle}} = h_w(x) \cdot e^{-\langle w, x\rangle}
        \]
        We first calculate $\frac{\partial h_w(x)}{\partial w}$:
        \begin{align*}
            \frac{\partial h_w(x)}{\partial w}
            &= (1 + e^{-\langle w, x\rangle})^{-2} \cdot e^{-\langle w, x\rangle} \cdot x\\
            &= h_w(x)^2 \cdot e^{-\langle w, x\rangle} \cdot x\\
            &= h_w(x)\cdot(1-h_w(x)) \cdot x\\
        \end{align*}
        Using chain rule, we can calculate $\frac{\partial f(w)}{\partial w}$:
        \begin{align*}
            \frac{\partial f(w)}{\partial w}
            &= -\frac{1}{m}\sum_{i=1}^{m}\left( y_i\cdot \frac{\partial \log(h_w(x_i))}{\partial w} + (1-y_i) \cdot \frac{\partial \log(1-h_w(x_i))}{\partial w}\right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m}\left( y_i\cdot \frac{1}{h_w(x_i)}\cdot\frac{\partial h_w(x_i)}{\partial w}
            - (1-y_i) \cdot \frac{1}{1-h_w(x_i)} \cdot \frac{\partial h_w(x_i)}{\partial w}\right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m} \left(y_i\cdot \frac{1}{h_w(x_i)}\cdot h_w(x_i)\cdot(1-h_w(x_i)) \cdot x_i
            - (1-y_i) \cdot \frac{1}{1-h_w(x_i)} \cdot h_w(x_i)\cdot(1-h_w(x_i)) \cdot x_i\right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m} \left(y_i\cdot (1-h_w(x_i)) \cdot x_i
            - (1-y_i) \cdot h_w(x_i) \cdot x_i\right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m} \left((y_i\cdot (1-h_w(x_i)) - (1-y_i) \cdot h_w(x_i))\cdot x_i \right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m} \left((y_i -y_i\cdot h_w(x_i) - h_w(x_i)+y_i \cdot h_w(x_i))\cdot x_i \right)\\
            &= -\frac{1}{m}\sum_{i=1}^{m} \left((y_i - h_w(x_i))\cdot x_i \right)\\
        \end{align*}
        Now we calculate the Hessian $\frac{\partial \frac{\partial f(w)}{\partial w}}{\partial w}$
        \begin{align*}
            \frac{\partial \frac{\partial f(w)}{\partial w}}{\partial w}
            &= \frac{1}{m}\sum_{i=1}^{m} \left(h_w(x_i)\cdot(1-h_w(x_i))\cdot x_i \cdot x_i^T \right)\\
        \end{align*}
    \end{homeworkSubsection}
    \begin{homeworkSubsection}{(b)}
        Observe that $0 < h_w(x_i) < 1$ for all $i = 1 \cdots m$ which means $h_w(x_i) > 0$ and $1 - h_w(x_i) > 0$.
        Furthermore, the term $x_i \cdot x_i^\top$ results in the a matrix which each entry is the square of the entries in $x_i$.
        This shows that the Hessian is positive semi-definite thus function is convex.
    \end{homeworkSubsection}
\end{homeworkProblem}
\end{document}
